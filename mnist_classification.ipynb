{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST SÄ±nÄ±flandÄ±rmasÄ±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¯ <b><u>Egzersiz hedefleri</u></b>\n",
    "- *MNIST* veri setini anlama \n",
    "- Ä°lk **EvriÅŸimli Sinir AÄŸÄ±nÄ±zÄ±** (*CNN*) tasarlama ve ÅŸu sorularÄ± yanÄ±tlama:\n",
    "    - *EvriÅŸim KatmanlarÄ±* nelerdir? \n",
    "    - bÃ¶yle bir katmanda kaÃ§ *parametre* bulunur?\n",
    "- Bu CNN'i gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde eÄŸitme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ <b><u>Hadi baÅŸlayalÄ±m!</u></b>\n",
    "\n",
    "ZamanÄ±nda 90'lara geri dÃ¶ndÃ¼ÄŸÃ¼mÃ¼zÃ¼ hayal edin.\n",
    "Bir *Postanede* Ã§alÄ±ÅŸÄ±yorsunuz ve gÃ¼nlÃ¼k olarak Ã§ok bÃ¼yÃ¼k miktarda mektupla uÄŸraÅŸmanÄ±z gerekiyor. 5 el yazÄ±sÄ± rakamÄ±n kombinasyonu olan Posta KodlarÄ±nÄ± okuma sÃ¼recini nasÄ±l otomatikleÅŸtirebilirsiniz?\n",
    "\n",
    "**El YazÄ±sÄ± TanÄ±ma** olarak adlandÄ±rÄ±lan bu gÃ¶rev, o gÃ¼nlerde Ã§ok karmaÅŸÄ±k bir problemdi. Bu problem, Derin Ã–ÄŸrenme gurularÄ±ndan biri olan [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun)'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± *Bell Labs* (ve diÄŸerleri) tarafÄ±ndan Ã§Ã¶zÃ¼ldÃ¼.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition)'dan:\n",
    "\n",
    "> El yazÄ±sÄ± tanÄ±ma (HWR), aynÄ± zamanda El YazÄ±sÄ± Metin TanÄ±ma (HTR) olarak da bilinir, bir bilgisayarÄ±n kaÄŸÄ±t belgeler, fotoÄŸraflar, dokunmatik ekranlar ve diÄŸer cihazlar gibi kaynaklardan gelen anlaÅŸÄ±labilir el yazÄ±sÄ± giriÅŸleri alabilme ve yorumlayabilme yeteneÄŸidir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SayÄ± tanÄ±ma](recognition.gif)\n",
    "\n",
    "*Not: YukarÄ±daki animasyon sadece farklÄ± gÃ¶rÃ¼ntÃ¼lerle ne olduÄŸunu gÃ¶rselleÅŸtirmenize yardÄ±mcÄ± olmak iÃ§in buradadÄ±r: <br/> $\\rightarrow$ Her gÃ¶rÃ¼ntÃ¼ iÃ§in, CNN eÄŸitildikten sonra hangi rakamÄ±n yazÄ±ldÄ±ÄŸÄ±nÄ± tahmin edecektir. GiriÅŸler farklÄ± rakamlar olup bir animasyon/video deÄŸildir!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤” <b><u>Bu CNN nasÄ±l Ã§alÄ±ÅŸÄ±r?</u></b>\n",
    "\n",
    "- *GiriÅŸler*: GÃ¶rÃ¼ntÃ¼ler (_her gÃ¶rÃ¼ntÃ¼ el yazÄ±sÄ± bir rakam gÃ¶sterir_)\n",
    "- *Hedef*: Her gÃ¶rÃ¼ntÃ¼ iÃ§in CNN modelinizin doÄŸru rakamÄ± (0 ile 9 arasÄ±nda) tahmin etmesini istiyorsunuz\n",
    "    - Bu bir **Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma** gÃ¶revidir (daha kesin olarak 10 farklÄ± rakam olduÄŸu iÃ§in 10 sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma gÃ¶revi).\n",
    "\n",
    "ğŸ”¢ EvriÅŸimli Sinir AÄŸÄ±nÄ±n bu sayÄ±larÄ± okuma kapasitesini geliÅŸtirmek iÃ§in, ona el yazÄ±sÄ± rakamlarÄ± temsil eden birÃ§ok gÃ¶rÃ¼ntÃ¼ beslemek gerekir. Bu nedenle ğŸ“š [**MNIST veri seti**](http://yann.lecun.com/exdb/mnist/) *(Karma Ulusal Standartlar ve Teknoloji EnstitÃ¼sÃ¼)* oluÅŸturulmuÅŸtur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) `MNIST` Veri Seti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š Tensorflow/Keras oynamak iÃ§in birden fazla [**veri seti**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) sunar:\n",
    "- *VektÃ¶rler*: `boston_housing` (regresyon)\n",
    "- *GÃ¶rÃ¼ntÃ¼ler* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (sÄ±nÄ±flandÄ±rma)\n",
    "- *Metinler*: `imbd`, `reuters` (sÄ±nÄ±flandÄ±rma/duygu analizi)\n",
    "\n",
    "\n",
    "ğŸ’¾ **MNIST veri setini** aÅŸaÄŸÄ±daki komutlarla **yÃ¼kleyebilirsiniz**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 11:56:35.189111: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-22 11:56:35.197048: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-22 11:56:35.264197: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-22 11:56:35.350489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-22 11:56:35.435331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-22 11:56:35.435955: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-22 11:56:35.556449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-22 11:56:36.580719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import datasets\n",
    "\n",
    "\n",
    "# Loading the MNIST Dataset...\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# The train set contains 60 000 images, each of them of size 28x28\n",
    "# The test set contains 10 000 images, each of them of size 28x28\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Veri setini keÅŸfetme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: Bu MNIST veri setindeki bazÄ± el yazÄ±sÄ± rakamlarÄ±na bakalÄ±m.** â“\n",
    "\n",
    "ğŸ–¨ *EÄŸitim setindeki* bazÄ± gÃ¶rÃ¼ntÃ¼leri yazdÄ±rÄ±n.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Ä°puÃ§larÄ±</i></summary>\n",
    "\n",
    "ğŸ’¡*Ä°pucu*: `matplotlib`'den `imshow` fonksiyonunu `cmap = \"gray\"` ile kullanÄ±n\n",
    "\n",
    "ğŸ¤¨ Not: Bu *cmap* argÃ¼manÄ±nÄ± belirtmezseniz, garip gÃ¶rÃ¼nen renkler sadece Matplotlib varsayÄ±lanlarÄ±dÄ±r...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FigÃ¼r boyutunu ayarlayalÄ±m (GeniÅŸlik, YÃ¼kseklik)\n",
    "plt.figure(figsize=(10, 2))\n",
    "\n",
    "# Ä°lk 5 gÃ¶rÃ¼ntÃ¼yÃ¼ dÃ¶ngÃ¼ ile gezelim\n",
    "for i in range(5):\n",
    "    # Yan yana 5 grafik Ã§izmek iÃ§in subplot kullanÄ±yoruz\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    \n",
    "    # i. gÃ¶rÃ¼ntÃ¼yÃ¼ (X_train[i]) gri tonlamalÄ± (cmap=\"gray\") olarak Ã§izelim\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    \n",
    "    # BaÅŸlÄ±ÄŸa o gÃ¶rÃ¼ntÃ¼nÃ¼n etiketini (y_train[i]) yazalÄ±m\n",
    "    plt.title(f\"Etiket: {y_train[i]}\")\n",
    "    \n",
    "    # Eksenleri kapatalÄ±m (daha temiz bir gÃ¶rÃ¼ntÃ¼ iÃ§in)\n",
    "    plt.axis('off')\n",
    "\n",
    "# GrafiÄŸi gÃ¶sterelim\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) GÃ¶rÃ¼ntÃ¼ Ã–n Ä°ÅŸleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸ **Sinir AÄŸlarÄ±, giriÅŸ verisi bir ÅŸekilde normalize edildiÄŸinde daha hÄ±zlÄ± yakÄ±nsama yapar** â—ï¸\n",
    "\n",
    "ğŸ‘©ğŸ»â€ğŸ« EvriÅŸimli Sinir AÄŸlarÄ± iÃ§in nasÄ±l devam ederiz?\n",
    "* `RGB` yoÄŸunluklarÄ± 0 ile 255 arasÄ±nda kodlanÄ±r. \n",
    "* GiriÅŸ verisini maksimum deÄŸer olan 255'e bÃ¶lerek tÃ¼m piksellerin yoÄŸunluklarÄ±nÄ± 0 ile 1 arasÄ±nda tutabiliriz ğŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru â“ Ä°lk Ã¶n iÅŸleme adÄ±mÄ± olarak lÃ¼tfen verilerinizi normalize edin.** \n",
    "\n",
    "Bunu hem eÄŸitim verilerinize hem de test verilerinize yapmayÄ± unutmayÄ±n.\n",
    "\n",
    "(*Not: tÃ¼m deÄŸerlerden 0.5 Ã§Ä±kararak verilerinizi merkezleyebilirsiniz de, ancak bu zorunlu deÄŸildir*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Maksimum deÄŸerin 255 olduÄŸunu biliyoruz, bu yÃ¼zden direkt bÃ¶lebiliriz.\n",
    "# BÃ¶lme iÅŸlemi sonucu otomatik olarak ondalÄ±klÄ± sayÄ±ya (float) dÃ¶nÃ¼ÅŸecektir.\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) GiriÅŸlerin boyutlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘† 60.000 eÄŸitim gÃ¶rÃ¼ntÃ¼nÃ¼z ve 10.000 test gÃ¶rÃ¼ntÃ¼nÃ¼z olduÄŸunu, her birinin $(28, 28)$ boyutunda olduÄŸunu hatÄ±rlayÄ±n. Ancak...\n",
    "\n",
    "> â—ï¸  **`EvriÅŸimli Sinir AÄŸÄ± modelleri, son boyutu kanal sayÄ±sÄ± olan gÃ¶rÃ¼ntÃ¼lerle beslenmelidir`.**  \n",
    "\n",
    "> ğŸ§‘ğŸ»â€ğŸ« ***ConvNet'lere*** beslenen tensÃ¶rlerin ÅŸekli ÅŸu ÅŸekildedir: `(GÃ–RÃœNTÃœ_SAYISI, YÃœKSEKLÄ°K, GENÄ°ÅLÄ°K, KANALLAR)`\n",
    "\n",
    "ğŸ•µğŸ»Bu son boyut burada aÃ§Ä±kÃ§a eksik. Nedenini tahmin edebilir misiniz?\n",
    "<br>\n",
    "<details>\n",
    "    <summary><i>Cevap<i></summary>\n",
    "        \n",
    "* TÃ¼m bu $60000$ $ (28 \\times 28) $ resim siyah-beyaz $ \\implies $ Her piksel tam siyahtan (0) tam beyaza (1) kadar bir spektrumda yaÅŸar.\n",
    "        \n",
    "    * Teorik olarak, siyah-beyaz bir resim iÃ§in kanal sayÄ±sÄ±nÄ± bilmenize gerek yoktur Ã§Ã¼nkÃ¼ yalnÄ±zca 1 kanal vardÄ±r (bir pikselin \"beyazlÄ±ÄŸÄ±\" veya \"siyahlÄ±ÄŸÄ±\"). Ancak, modelin bu kanal sayÄ±sÄ±nÄ± aÃ§Ä±k olarak belirtmesi yine de zorunludur.\n",
    "        \n",
    "    * KarÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, renkli resimler birden fazla kanala ihtiyaÃ§ duyar:\n",
    "        - 3 kanallÄ± RGB sistemi (<b><span style=\"color:red\">KÄ±rmÄ±zÄ±</span> <span style=\"color:green\">YeÅŸil</span> <span style=\"color:blue\">Mavi</span></b>)\n",
    "        - 4 kanallÄ± CYMK sistemi (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">SarÄ±</span> <span style=\"color:black\">Siyah</span></b>)\n",
    "        \n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: boyutlarÄ± geniÅŸletme** â“\n",
    "\n",
    "* EÄŸitim verisi ve test verisinin sonuna bir boyut eklemek iÃ§in **`expand_dims`** kullanÄ±n.\n",
    "\n",
    "* ArdÄ±ndan, `X_train` ve `X_test`'in ÅŸekillerini yazdÄ±rÄ±n. Bunlar sÄ±rasÄ±yla $(60000, 28, 28, 1)$ ve $(10000, 28, 28, 1)$'e eÅŸit olmalÄ±dÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.ops import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EÄŸitim seti ÅŸekli: (60000, 28, 28, 1)\n",
      "Test seti ÅŸekli:   (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# axis=-1 demek, boyutu en sona (son eksene) ekle demektir.\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Åekilleri kontrol edelim\n",
    "print(\"EÄŸitim seti ÅŸekli:\", X_train.shape)\n",
    "print(\"Test seti ÅŸekli:  \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Hedef kodlama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derin Ã–ÄŸrenmede Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma gÃ¶revi iÃ§in yapÄ±lacak bir ÅŸey daha:\n",
    "\n",
    "ğŸ‘‰ _Kategorileri \"one-hot-encode\" etme_\n",
    "\n",
    "â“ **Soru: etiketleri kodlama** â“ \n",
    "\n",
    "* Etiketlerinizi dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in **`to_categorical`** kullanÄ±n. \n",
    "* SonuÃ§larÄ± **`y_train_cat`** ve **`y_test_cat`** adÄ±nÄ± verebileceÄŸiniz iki deÄŸiÅŸkende saklayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal etiket (ilk Ã¶rnek): 5\n",
      "DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ etiket (ilk Ã¶rnek): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "y_train_cat ÅŸekli: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# 10 farklÄ± rakamÄ±mÄ±z (sÄ±nÄ±fÄ±mÄ±z) olduÄŸu iÃ§in num_classes=10 diyoruz\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# DeÄŸiÅŸimi gÃ¶rmek iÃ§in bir Ã¶rneÄŸe bakalÄ±m\n",
    "print(f\"Orijinal etiket (ilk Ã¶rnek): {y_train[0]}\")\n",
    "print(f\"DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ etiket (ilk Ã¶rnek): {y_train_cat[0]}\")\n",
    "\n",
    "# Åekilleri kontrol edelim\n",
    "print(\"y_train_cat ÅŸekli:\", y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check that you correctly used to_categorical\n",
    "assert(y_train_cat.shape == (60000,10))\n",
    "assert(y_test_cat.shape == (10000,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri artÄ±k kullanÄ±lmaya hazÄ±r. âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) EvriÅŸimli Sinir AÄŸÄ±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) CNN'in mimarisi ve derlenmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: CNN Mimarisi ve derleme** â“\n",
    "\n",
    "Åimdi, ÅŸunlara sahip bir <u>EvriÅŸimli Sinir AÄŸÄ±</u> oluÅŸturalÄ±m: \n",
    "\n",
    "\n",
    "- 8 filtresi olan bir `Conv2D` katmanÄ±, her biri $(4, 4)$ boyutunda, gÃ¶reviniz iÃ§in uygun bir giriÅŸ ÅŸekli, `relu` aktivasyon fonksiyonu ve `padding='same'`\n",
    "- `pool_size`'Ä± $(2, 2)$'ye eÅŸit olan bir `MaxPool2D` katmanÄ±\n",
    "- 16 filtresi olan ikinci bir `Conv2D` katmanÄ±, her biri $(3, 3)$ boyutunda ve `relu` aktivasyon fonksiyonu\n",
    "- `pool_size`'Ä± $(2, 2)$'ye eÅŸit olan ikinci bir `MaxPool2D` katmanÄ±\n",
    "\n",
    "\n",
    "- bir `Flatten` katmanÄ±\n",
    "- 10 nÃ¶ronu olan ve `relu` aktivasyon fonksiyonuna sahip ilk `Dense` katman\n",
    "- gÃ¶reviniz iÃ§in uygun olan son (tahmin edici) katman\n",
    "\n",
    "Bu modeli baÅŸlatan fonksiyonda, <u>modelin derlenmesini</u> de dahil etmeyi unutmayÄ±n:\n",
    "* `categorical_crossentropy` kayÄ±p fonksiyonunu optimize eder,\n",
    "* `adam` optimizer ile, \n",
    "* ve metrik olarak `accuracy`\n",
    "\n",
    "(*Not: isterseniz daha fazla sÄ±nÄ±flandÄ±rma metriÄŸi ekleyebilirsiniz ama veri seti dengeli!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def initialize_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ### First Convolution & MaxPooling\n",
    "    # GiriÅŸ ÅŸekli (28, 28, 1) olarak belirtilmeli Ã§Ã¼nkÃ¼ bu ilk katman.\n",
    "    # 8 filtre, 4x4 Ã§ekirdek boyutu, 'same' padding (boyut korumak iÃ§in)\n",
    "    model.add(layers.Conv2D(8, (4, 4), input_shape=(28, 28, 1), activation='relu', padding='same'))\n",
    "    \n",
    "    # Havuzlama katmanÄ±: GÃ¶rÃ¼ntÃ¼ boyutunu yarÄ±ya indirir\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    ### Second Convolution & MaxPooling\n",
    "    # 16 filtre, 3x3 Ã§ekirdek boyutu\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "    \n",
    "    # Ä°kinci havuzlama\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    ### Flattening\n",
    "    # 2D/3D matrisleri tek bir uzun vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ### One Fully Connected layer\n",
    "    # Ara katman\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "    ### Last layer - Classification Layer\n",
    "    # 10 sÄ±nÄ±fÄ±mÄ±z olduÄŸu iÃ§in 10 nÃ¶ron.\n",
    "    # Ã‡oklu sÄ±nÄ±flandÄ±rma (Multi-class) olduÄŸu iÃ§in 'softmax' aktivasyonu.\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    ### Model compilation\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Modeli baÅŸlatÄ±p Ã¶zetini gÃ¶relim\n",
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: evriÅŸim katmanÄ±ndaki eÄŸitilebilir parametrelerin sayÄ±sÄ±** â“ \n",
    "\n",
    "Modelinizde kaÃ§ eÄŸitilebilir parametre var?\n",
    "1. Ã–nce ***model.summary( )*** ile hesaplayÄ±n\n",
    "2. ***CNN'deki aÄŸÄ±rlÄ±k sayÄ±sÄ±nÄ± neyin etkilediÄŸini*** doÄŸru anladÄ±ÄŸÄ±nÄ±zdan emin olmak iÃ§in bunlarÄ± elle yeniden hesaplayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,770</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚           \u001b[38;5;34m136\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m16\u001b[0m)     â”‚         \u001b[38;5;34m1,168\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m5,770\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m110\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,184</span> (28.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,184\u001b[0m (28.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,184</span> (28.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,184\u001b[0m (28.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) CNN'i eÄŸitme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: CNN'i eÄŸitme** â“ \n",
    "\n",
    "Modelinizi baÅŸlatÄ±n ve eÄŸitim verisi Ã¼zerinde eÄŸitin. \n",
    "- **DoÄŸrulama Seti/BÃ¶lÃ¼nmesi** ve **Erken Durdurma kriteri** kullanmayÄ± unutmayÄ±n. \n",
    "- Bu meydan okumada kendinizi maksimum 5 epoch ile sÄ±nÄ±rlayÄ±n, sadece daha geliÅŸmiÅŸ meydan okumalar iÃ§in deÄŸerli zamanÄ± korumak iÃ§in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.4998 - val_accuracy: 0.9508 - val_loss: 0.1578\n",
      "Epoch 2/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1262 - val_accuracy: 0.9650 - val_loss: 0.1112\n",
      "Epoch 3/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0888 - val_accuracy: 0.9722 - val_loss: 0.0868\n",
      "Epoch 4/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0705 - val_accuracy: 0.9768 - val_loss: 0.0780\n",
      "Epoch 5/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0615 - val_accuracy: 0.9784 - val_loss: 0.0722\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 1. Modeli baÅŸlatalÄ±m\n",
    "model = initialize_model()\n",
    "\n",
    "# 2. Erken Durdurma (Early Stopping) tanÄ±mlayalÄ±m\n",
    "# monitor='val_loss': DoÄŸrulama setindeki hatayÄ± izle\n",
    "# patience=2: Hata 2 epoch boyunca dÃ¼ÅŸmezse dur\n",
    "# restore_best_weights=True: EÄŸitim bittiÄŸinde en iyi aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kle\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# 3. EÄŸitimi baÅŸlatalÄ±m\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train_cat, \n",
    "    epochs=5,                # Soru gereÄŸi 5 ile sÄ±nÄ±rladÄ±k\n",
    "    batch_size=32,           # Her seferde 32 gÃ¶rÃ¼ntÃ¼ iÅŸlenecek\n",
    "    validation_split=0.3,    # Verinin %30'u doÄŸrulama iÃ§in ayrÄ±ldÄ±\n",
    "    callbacks=[es],          # Erken durdurmayÄ± ekledik\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: CNN epoch baÅŸÄ±na kaÃ§ iterasyon gerÃ§ekleÅŸtirir** â“\n",
    "\n",
    "_Not: bunun CNN olmasÄ±yla alakasÄ± yoktur. Bu, optimizer'lar, fitting ve kayÄ±plar Ã¼zerine Ã¶nceki derste zaten kapsanan ileri/geri yayÄ±lÄ±m kavramÄ±yla ilgilidir ğŸ˜‰_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> CEVABINIZI BURAYA YAZIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Cevap</i></summary>\n",
    "\n",
    "Modelinizi eÄŸitirken `verbose = 1` ile eÄŸitim prosedÃ¼rÃ¼nÃ¼z hakkÄ±nda Ã¶nemli bilgilere eriÅŸebilirsiniz.\n",
    "    \n",
    "CNN modelimizi $60000$ eÄŸitim gÃ¶rÃ¼ntÃ¼sÃ¼ Ã¼zerinde eÄŸittiÄŸimizi hatÄ±rlayÄ±n\n",
    "\n",
    "SeÃ§ilen batch size 32 ise: \n",
    "\n",
    "* Her epoch iÃ§in $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ mini batch'e sahibiz <br/>\n",
    "* _validation_split_ $0.3$'e eÅŸittir - bu da tek bir epoch iÃ§inde ÅŸu anlama gelir:\n",
    "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batch `train_loss` hesaplamak iÃ§in kullanÄ±lÄ±r \n",
    "    * $ 1875 - 1312 = 562 $ batch `val_loss` hesaplamak iÃ§in kullanÄ±lÄ±r\n",
    "    * **Parametreler epoch baÅŸÄ±na 1313 kez gÃ¼ncellenir** Ã§Ã¼nkÃ¼ epoch baÅŸÄ±na 1313 ileri/geri yayÄ±lÄ±m vardÄ±r !!!\n",
    "\n",
    "\n",
    "ğŸ‘‰ Bir epoch iÃ§inde aÄŸÄ±rlÄ±klarÄ±n bu kadar fazla gÃ¼ncellemesi ile, bu CNN modelinin sÄ±nÄ±rlÄ± sayÄ±da epoch ile bile yakÄ±nsadÄ±ÄŸÄ±nÄ± anlayabilirsiniz.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) PerformansÄ±nÄ± deÄŸerlendirme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: CNN'inizi deÄŸerlendirme** â“ \n",
    "\n",
    "**`Test setindeki doÄŸruluÄŸunuz`** nedir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (KayÄ±p): 0.0596\n",
      "Test Accuracy (DoÄŸruluk): 98.11%\n"
     ]
    }
   ],
   "source": [
    "# verbose=0: Ä°ÅŸlem Ã§ubuÄŸunu gizler (sadece sonucu gÃ¶rmek iÃ§in)\n",
    "results = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"Test Loss (KayÄ±p): {results[0]:.4f}\")\n",
    "print(f\"Test Accuracy (DoÄŸruluk): {results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‰ CNN becerilerinizle ÅŸimdiden etkilenmiÅŸ olmalÄ±sÄ±nÄ±z! %95'in Ã¼zerinde doÄŸruluÄŸa ulaÅŸmak!\n",
    "\n",
    "ğŸ”¥ 30 yÄ±l Ã¶nce Ã§ok zor olan bir problemi kendi CNN'iniz ile Ã§Ã¶zdÃ¼nÃ¼z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ **Tebrikler!**\n",
    "\n",
    "ğŸ’¾ Notebook'unuzu `git add/commit/push` yapmayÄ± unutmayÄ±n...\n",
    "\n",
    "ğŸš€ ... ve bir sonraki projeye geÃ§in!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workintech_current",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
